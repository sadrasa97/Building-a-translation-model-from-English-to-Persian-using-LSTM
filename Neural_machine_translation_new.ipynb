{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# install packages"
      ],
      "metadata": {
        "id": "cbz7mR4Yn-zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchtext==0.15.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-a2WAK1nxKq",
        "outputId": "53e1e9dd-6d09-4e74-8291-476b561e6ff7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.2)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nvhBqUdkKj-A",
        "outputId": "af5fe0e4-6c16-4066-ec92-f76db2489789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting flashtext<3.0,>=2.7 (from hazm)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.9.1)\n",
            "Collecting numpy==1.24.3 (from hazm)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.6.0)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (75.1.0)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.0.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.17.0)\n",
            "Downloading hazm-0.10.0-py3-none-any.whl (892 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9298 sha256=6e34e6251d0d72182e9d3695911a98dda11b08c5b8129009c0ff54d22689a81e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext, python-crfsuite, pybind11, numpy, fasttext-wheel, hazm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 hazm-0.10.0 numpy-1.24.3 pybind11-2.13.6 python-crfsuite-0.9.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "f7a509a22f064e85979f525c62658b77"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install spacy\n",
        "!pip install transformers\n",
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import packages"
      ],
      "metadata": {
        "id": "1He8zuJgoG_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4S3YyHDapgno"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable, List\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from transformers import AutoTokenizer\n",
        "import sentencepiece as spm\n",
        "from torch.nn import Embedding\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from transformers import MBartTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural machine Translation"
      ],
      "metadata": {
        "id": "fl9i_lkxoLUW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_2S4KYRLLNJ"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "60367ad3c26f40bc9a7ca99b528ec3f1",
            "2712798c358347c89f979ffd06450bf3",
            "09c8115dd5e0475fbf4c7c39bf89725f",
            "7264731988124b0db16e9bba010633ff",
            "3f8ff5003b6e48339788d7c94e7f84b1",
            "676792d4c0de4a3eb4608aaae50dde0e",
            "583fa59f4bdc45e99fd4e0b5fb60f991",
            "0ee6d33e94f44ebaaab513f8111e01f0",
            "ed2a2e54bf9e4af1bbeded029bcc850f",
            "7641edf42be04e92b8d18f40c57998b2",
            "7ba86dd3dce24946b0d15a4286d823c1",
            "68b64518e96946b19a4f2b9acb24d75c",
            "07abd35f89b74ce3971fe0c8d8acf5e2",
            "b4023bb5354a41fc963a09a092505822",
            "216bbd5713ad451c822ee3368fd44370",
            "2f024a750f9d44b5b468dcdf340d394e",
            "7df47677ca6c4ad1830da124ea4c3365",
            "6092e1d915af468f9800e7f30959f906",
            "2c3acc7164464644ae9ab8b7bf924b1c",
            "cda6ae5c0f0245a3beac0bbd41b7da92",
            "22849f9a3d6643729e00559a1de58095",
            "d3d5bc169c52484697d5ec9dc94ff37b",
            "c75621b4437a4372bde748a433dd9626",
            "8340ee1ff41244bc8401ba22b654d5c3",
            "55f7e8b09e4f4ea384997ee102cc6db0",
            "6998f094d925466e9575ffda8fd52f97",
            "9f9d3368ef644ceba6663550f9909aa1",
            "c14af2617c08456999324464cc84bb87",
            "0bf9bd3833434b55a0a16f8cfb99a9b1",
            "86e0f091cdf34259958c67770ce07cad",
            "1527b9e30cda4b2cbcd040156ce7d381",
            "05dda08b2cae4b409fca351e19977883",
            "ea3ae63b9ce044518eb3229541e4616e",
            "8351df7c6f624b2892e87358bcb92f41",
            "6985091be50d426d91009da8de52b038",
            "875947564b8f4a7c98f7e5dfa1222c34",
            "0ecc4bc9efb64204bc87acb85e1edd7c",
            "f63677da0dcd4a8d85bbbe9852fd4de9",
            "dba18a5e4ffb4af48018b8898d45dec1",
            "25ebe9545a83410e868f783c88f396f4",
            "d0ad12e94e8848f39f2bf2152dc1f476",
            "ed382e4926bc477faf34990d7323c763",
            "926e71d1736948f99e4be5323ed8f62c",
            "9b19459bf8e1440097ef489c9c1f64a6",
            "b2d46912ad9c47f6a6df36ca64bbeb2c",
            "75ef79547c024b568766375a347f6fd4",
            "2cd971faf2664aab9961f96e80df3fc5",
            "da60603efa914bc78902be738698b816",
            "70624d702f24491d9ecc7174fd18ced2",
            "bfb40f7be31e45a8a40bab961aa46f9d",
            "cad0794112424eef8afdd00d1aa1cada",
            "e6aeafafc56b4807aeb1bd72c387987d",
            "90e87b3d475c4fd8b4012f8f27ce51c6",
            "f7b317f0e0d74c3a85a7db17c5c54929",
            "0a24f698277e449dac7fcf86e73e6c0d",
            "653943bf2c624dd8a003fcc37ecc0426",
            "1c4215ae641f4e0a8182fed831749dd9",
            "0691772a493d4e91a83acbc9d5db0dcc",
            "746e1e2dae3144c1adf4c663bffac599",
            "46dba8783456476ea17bdd6ad56821c7",
            "601b32f9b2604524be83e0f1e498aef2",
            "9122f8a472434a12b67fe9739367bbf8",
            "894b9724659a46939873e1a86cc910d6",
            "4feadb96112545ae8c770f5baea3b560",
            "d13540c5874d4cb388a739a6c0cda21b",
            "70a04e840892460ea9870215fd63ba28",
            "7e4f4694f93f4b40a90d968171ca531b",
            "0a5111503103476eaf9f2cf3be370d61",
            "a7b48bb76bba46dead8196f842621b39",
            "172384085cfc4ff2bb64475917a2f1ef",
            "7e4f8016a2f54189bd79438d5a792184",
            "3d9984c5bb92496a8cfa7b46d4f3dac8",
            "8252b057178644e58a0833d99f53cb9e",
            "01c7ff97409546f78bb9ba9c914e670d",
            "298821f77c0a4de0bbbaacdbd9ab74f6",
            "a68b81ee78a042c39f8a77c55d1bbf9c",
            "93e0cc221bdd4c8a9b01e53c9e968c05",
            "e8a72eda82c9403e8975e1994563c687",
            "f63d61b1ed9c435dbaf0d7813d15dd48",
            "0e57ec84daf04ec2aada45c14142ff8a",
            "f58c3967cf944353900a0af28f3844c2",
            "60b2e0da790d4891bb37cdf2df5df586",
            "82dbc1bb964e405196161bc0e001099c",
            "cfd464d511fd4cbe8ec4bf21b3a126b1",
            "aae6615de4204e1b8004ee8497b2a388",
            "0c08903ba50c4b53a201e1c116524988",
            "98f5d6e68016475f92c91b6071fba502",
            "2953d7edb1104c15af391e71cff74ce9"
          ]
        },
        "id": "5u932CRWH0Aj",
        "outputId": "30d754e6-bbfd-47c5-c1e5-cadb859cafe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60367ad3c26f40bc9a7ca99b528ec3f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "parsinlu_translation_en_fa.py:   0%|          | 0.00/5.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68b64518e96946b19a4f2b9acb24d75c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75621b4437a4372bde748a433dd9626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8351df7c6f624b2892e87358bcb92f41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "parsinlu-repo/validation/0000.parquet:   0%|          | 0.00/242k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2d46912ad9c47f6a6df36ca64bbeb2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1621665 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "653943bf2c624dd8a003fcc37ecc0426"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/48359 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e4f4694f93f4b40a90d968171ca531b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2137 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8a72eda82c9403e8975e1994563c687"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample English-Persian sentence pair:\n",
            "{'source': 'Due Thank You note by Egyptian blogger Abdel Monem Mahmoud: Following his release from prison, he wrote his first blog titled “Ana ikhwan… I am free”.', 'targets': ['بلاگر مصری عبدل منعم محمود (عربی) پس از آزاد شدنش از زندان تیتر اولین مطلب خود را «من آزاد هستم» (عربی) انتخاب کرد.'], 'category': 'global_voices_en_fa'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the Global Voices English-Persian translation dataset\n",
        "dataset = load_dataset(\"persiannlp/parsinlu_translation_en_fa\", split='train')\n",
        "\n",
        "# Print a sample of the dataset\n",
        "print(\"Sample English-Persian sentence pair:\")\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "on-Aj6p5IBv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252eceb8-7ea3-43b6-8462-034f57dd7e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the subset: 60000\n",
            "First English sentence: She ventured to ask: Is it true, Madame?\n",
            "First Persian sentence: دل بدریا زد پرسید: خانم، این راسته؟\n"
          ]
        }
      ],
      "source": [
        "# Randomly sample 20,000 examples from the dataset\n",
        "sample_size = 60000\n",
        "sampled_dataset = dataset.shuffle(seed=42).select(range(sample_size))\n",
        "\n",
        "# Extract English and Persian sentences\n",
        "english_sentences = [item['source'] for item in sampled_dataset]\n",
        "persian_sentences = [item['targets'][0] for item in sampled_dataset]\n",
        "\n",
        "print(f\"Number of samples in the subset: {len(english_sentences)}\")\n",
        "print(\"First English sentence:\", english_sentences[0])\n",
        "print(\"First Persian sentence:\", persian_sentences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yXm8a3cOrjF"
      },
      "source": [
        "## Train valid Test split & Creating Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5IIDHYWIKta",
        "outputId": "91c3eb3e-5a9d-4bfe-a73a-2efa9781de0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 54000\n",
            "Number of validation samples: 2400\n",
            "Number of testing samples: 3600\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the proportion for the train-test split\n",
        "test_size = 0.10  # 20% of data for testing\n",
        "random_seed = 42  # For reproducibility\n",
        "\n",
        "# Split the data into train and test sets\n",
        "english_train, english_test, persian_train, persian_test = train_test_split(\n",
        "    english_sentences, persian_sentences, test_size=test_size, random_state=random_seed\n",
        ")\n",
        "\n",
        "english_test, english_valid, persian_test, persian_valid = train_test_split(\n",
        "    english_test, persian_test, test_size=0.4, random_state=random_seed\n",
        ")\n",
        "\n",
        "# Display the size of each split\n",
        "print(f\"Number of training samples: {len(english_train)}\")\n",
        "print(f\"Number of validation samples: {len(english_valid)}\")\n",
        "print(f\"Number of testing samples: {len(english_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class for English-Persian translation\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_data, tgt_data):\n",
        "        self.src_data = src_data\n",
        "        self.tgt_data = tgt_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src_data[idx], self.tgt_data[idx]\n",
        "# Create Dataset\n",
        "train_dataset = TranslationDataset(english_train, persian_train)\n",
        "valid_dataset = TranslationDataset(english_valid, persian_valid)\n",
        "test_dataset = TranslationDataset(english_test, persian_test)"
      ],
      "metadata": {
        "id": "zCZ_kTUYH51x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build vocabulary"
      ],
      "metadata": {
        "id": "_BVflQalDKK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wvm9SZEfjysq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "21757c62902e4682b747d9ac89bcd354",
            "1c6b7fc7fca8428aa66f9d4f1969ef7e",
            "c6e34b0419864143a77c2669ee98a556",
            "877bd4413bb343d2a567f52a56b63d42",
            "ed0dc06f55f144ec840c2a6b85b53982",
            "a21e4f9d0fbd4ef193ab3cfbe6af41cc",
            "5cc69f9ee8044e6ea0c63ddfd002b803",
            "06c38bd22899475ca7e2bce7b094d3c3",
            "34672cd1d0114a3cb5d06a60966f4ead",
            "132f43b532ee43eb91bb132af7a4e03d",
            "6714559bb0464c57b99db2c85b51d6c5",
            "c10d232d61194cb7ae343773b1de29df",
            "344281bdccf94708bf5edec6c387b8c5",
            "cd0c14d461bd4bdc8ed813278517cfef",
            "6c41a6c095de45bb909b5d47f22beffb",
            "93866bd321ac4ca59efcff11b0366b19",
            "d90488802fc641b58702f6274d7ff0a9",
            "ec8feee5ce4245a68a134f762d14cb9c",
            "f016278a9c484ee0a3a8db6556cd4abe",
            "3b31ac34d4664489ba89bccf34d20eb1",
            "b15845a7ccac4df38a9eb62c05cee6eb",
            "6d37806b118a44c4ab26d76a00afc28f",
            "8c2ceacdbe79419b99a1b218b15ed256",
            "44380ca694114e59a192208fdb85df54",
            "087afec00fd94d5b840f64551eaf46ba",
            "a4be715bc7c145a9a87a36a716ccb671",
            "fb8f5bec7db84f7eb3b48a6ec7707c59",
            "ddfdc3bbd4fd492097392411315bf0ae",
            "3158098b2542492a89e4465a0b180ea8",
            "889ae9d37f13421fb0be55efac8d0448",
            "660788cf4d584786be40f660556fd78f",
            "3f46574cdf0d41a0bd0cdf3a3982141f",
            "8cca3c75d5b94a81898d3bffa37dd2e0",
            "04760e2ef19240f28e88964e54a2f495",
            "386a67706ce148328c76b54ad9f47759",
            "a11017314f0d40228ac602179f7ecc5b",
            "0338c612161f4667ad31321207eb03c1",
            "3b0e47c78d3b4dfe94bdb358246a1dce",
            "430b98c4e5284e17b0dd4b6d15a5446f",
            "cb85e1c467db4c76974b0a19d3ccc7c8",
            "bc1062b891084fea9bac9fb63096620c",
            "fd9aff1f51874519b83a555171cde809",
            "5f072453cf544de0b59664d3f4c2ecbe",
            "e32bca3f34e94d4d9a01e285899b535a"
          ]
        },
        "outputId": "700e21f0-9334-447c-c658-95ac1f3c65fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21757c62902e4682b747d9ac89bcd354"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c10d232d61194cb7ae343773b1de29df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c2ceacdbe79419b99a1b218b15ed256"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04760e2ef19240f28e88964e54a2f495"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
            "The class this function is called from is 'MBartTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
            "The class this function is called from is 'MBartTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "token_transform = {}\n",
        "mb = MBartTokenizer.from_pretrained(\"facebook/mbart-large-50\")  # Initialize MBartTokenizer\n",
        "def en_tokenize(sentence):\n",
        "    return mb.tokenize(sentence)\n",
        "\n",
        "token_transform['en'] = en_tokenize\n",
        "\n",
        "token_transform = {}\n",
        "mb = MBartTokenizer.from_pretrained(\"facebook/mbart-large-50\")  # Initialize MBartTokenizer\n",
        "def en_tokenize(sentence):\n",
        "    return mb.tokenize(sentence)\n",
        "\n",
        "token_transform['en'] = en_tokenize\n",
        "\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('/content/persian_spm.model')\n",
        "# Define the tokenization function using SentencePiece\n",
        "def persian_tokenize(sentence):\n",
        "    return sp.tokenize(sentence, out_type=str)\n",
        "token_transform['fa'] = persian_tokenize\n",
        "# تعریف نمادهای ویژه\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "# دیکشنری برای ذخیره واژگان هر زبان\n",
        "vocab_transform = {}\n",
        "\n",
        "# تابعی برای ایجاد توکن‌ها از داده‌ها\n",
        "# Function to yield individual tokens (one by one)\n",
        "def yield_tokens(data_iter, language: str):\n",
        "    language_index = {'en': 0, 'fa': 1}\n",
        "    for i,data_sample in enumerate(data_iter):\n",
        "\n",
        "        yield token_transform[language](data_sample[language_index[language]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ln in ['fa', 'en']:\n",
        "    print(f\"Building vocabulary for {ln}...\")\n",
        "    # Create training iterator\n",
        "    train_iterator = list(zip(english_train, persian_train))\n",
        "    sorted_dataset = sorted(train_iterator, key=lambda x: len(x[0].split()))  # Sort by sentence length\n",
        "\n",
        "    # Build vocabulary\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(\n",
        "        yield_tokens(sorted_dataset, ln),\n",
        "        specials=special_symbols,\n",
        "        special_first=True\n",
        "    )\n",
        "\n",
        "# Set default index for both vocabularies\n",
        "vocab_transform['en'].set_default_index(UNK_IDX)\n",
        "vocab_transform['fa'].set_default_index(UNK_IDX)\n",
        "\n",
        "en_vocab_size = len(vocab_transform['en'])\n",
        "fa_vocab_size = len(vocab_transform['fa'])\n",
        "# Print vocab size for verification\n",
        "print(\"English vocab size:\",en_vocab_size )\n",
        "print(\"Persian vocab size:\",fa_vocab_size)\n",
        "\n",
        "print(list(vocab_transform['fa'].get_stoi().keys())[-10:])\n",
        "print(list(vocab_transform['en'].get_stoi().keys())[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyhYjEMY_5i9",
        "outputId": "e860f561-2254-4653-a2eb-32c10fc09514"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building vocabulary for fa...\n",
            "Building vocabulary for en...\n",
            "English vocab size: 16059\n",
            "Persian vocab size: 19855\n",
            "['▁میاره', 'خود', '▁میافته', 'ورز', '▁تل', '▁میخواستم', '▁میدم', '▁بپذیریم', '▁دني', '▁میگیرم']\n",
            "['▁نگار', '▁zen', '▁yuz', '▁yuk', '▁yin', '▁yay', '▁winst', '▁welches', '▁websites', '▁waka', '▁vu', '▁volt', '▁volatil', '▁voce', '▁visa', '▁violation', '▁vim', '▁vidu', '▁vibrant', '▁versus', '▁vero', '▁verbo', '▁vente', '▁vendor', '▁vender', '▁£', '▁vall', '▁uz', '▁utili', '▁usa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_transform['en'](['I','▁like','▁machine','▁learning']))\n",
        "sentence1= \"من عاشق کتابها هستم\"\n",
        "sentence2= \"من\"\n",
        "print(token_transform['fa'](sentence1))\n",
        "print(vocab_transform['fa'](token_transform['fa'](sentence1)))\n",
        "print(vocab_transform['fa'](token_transform['fa'](sentence2)))"
      ],
      "metadata": {
        "id": "CufS33Z4qOBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335a64f0-8730-4d3e-9f56-9f7b3771699d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[584, 72, 3192, 3548]\n",
            "['▁من', '▁عاشق', '▁کتابها', '▁هستم']\n",
            "[17, 778, 14307, 253]\n",
            "[17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data to input model\n",
        "we make  train_dataloader and  valid_dataloader in this step."
      ],
      "metadata": {
        "id": "v_iXCVlCC4NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensor transforms"
      ],
      "metadata": {
        "id": "wH6CUZpQDY97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor_transform_s:\n",
        "این تابع برای پردازش جملات منبع (مانند انگلیسی در ترجمه انگلیسی به فارسی) برای یک مدل دنباله به دنباله استفاده می‌شود.\n",
        "    \n",
        "    1- BOS_IDX:  ‌توکن \"آغاز دنباله\" را به ابتدای جمله اضافه کنید.\n",
        "\n",
        "\n",
        "    2- reversing tokens:\n",
        "     توکن‌های ورودی را معکوس کنید. این معمولاً برای دنباله‌های منبع در برخی از مدل‌های دنباله به دنباله انجام می‌شود، مانند برخی از انواع ترجمه ماشینی عصبی  تا مدل کاراتر شود.\n",
        "\n",
        "            در برخی از مدل‌های ترجمه ماشینی عصبی ، عملیات برعکس کردن دنباله‌های ورودی (مانند جملات منبع) به‌ویژه برای مدل‌های دنباله به دنباله انجام می‌شود. این کار به دلیل دلایل مختلفی صورت می‌گیرد:\n",
        "\n",
        "            بهبود یادگیری مدل: با برعکس کردن دنباله‌ها، مدل قادر خواهد بود روابط بلندمدت و وابستگی‌های طولانی‌تر را به‌خوبی یاد بگیرد. این تکنیک به‌ویژه در زمانی که ورودی‌ها وابستگی‌های طولانی دارند، مفید است.\n",
        "\n",
        "            تسهیل پردازش وابستگی‌ها: در مدل‌های بازگشتی ، توکن‌های انتهایی ممکن است برای پیش‌بینی توکن‌های ابتدایی مفید باشند. برعکس کردن دنباله‌ها این امر را برای مدل راحت‌تر می‌کند تا وابستگی‌های مهم را شناسایی کرده و پردازش کند.\n",
        "\n",
        "            اهمیت ترتیب توکن‌ها: برعکس کردن دنباله‌ها ممکن است به مدل کمک کند تا ویژگی‌های ساختاری زبان‌های مختلف را به‌خوبی یاد بگیرد، به‌ویژه در مواردی که ترتیب توکن‌ها در زبان‌های مختلف اهمیت دارد.\n",
        "\n",
        "            این تکنیک به‌طور خاص در مدل‌هایی مانند ترجمه ماشینی استفاده می‌شود تا یادگیری وابستگی‌های متنی بهتر انجام شود و مدل به دقت بیشتری دست یابد.\n",
        "\n",
        "    \n",
        "    3- EOS_IDX:  توکن \"پایان دنباله\" را به انتهای جمله اضافه کنید.\n",
        "\n",
        "tensor_transform_t:\n",
        "این تابع برای جملات هدف (مانند فارسی) استفاده می‌شود.\n",
        "\n",
        "   \n",
        "    ۱- BOS_IDX: یک توکن \"آغاز دنباله\" را اضافه می‌کند.\n",
        "\n",
        "    ۲- بدون برعکس کردن: جملات هدف معمولاً در همان ترتیب خود نگه‌داشته می‌شوند.\n",
        "   \n",
        "    ۳- EOS_IDX: یک توکن \"پایان دنباله\" را به انتهای جمله اضافه می‌کند.\n",
        "\n",
        "این تبدیل‌ها اطمینان می‌دهند که جملات به درستی توکنایز شده و برای شبکه عصبی ساختاربندی شده‌اند.\n",
        "\n",
        "تابع sequential_transforms:\n",
        "\n",
        "این تابع به شما این امکان را می‌دهد که چندین تبدیل را به‌صورت زنجیره‌ای به هم متصل کنید، به طوری که این تبدیل‌ها به ترتیب بر روی متن ورودی اعمال شوند. این تابع چندین تابع تبدیل را می‌گیرد و آن‌ها را به ترتیبی که ارسال شده‌اند، اعمال می‌کند."
      ],
      "metadata": {
        "id": "iMPDoNwgDgWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenization and vocabulary for both languages\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'fa'\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Transform functions for source and target tokens\n",
        "def tensor_transform_s(token_ids: List[int]):\n",
        "    return torch.cat((\n",
        "        torch.tensor([BOS_IDX]),\n",
        "        torch.tensor(token_ids[::-1]),\n",
        "        torch.tensor([EOS_IDX])\n",
        "    ))\n",
        "\n",
        "def tensor_transform_t(token_ids: List[int]):\n",
        "    return torch.cat((\n",
        "        torch.tensor([BOS_IDX]),      # Add beginning-of-sequence token\n",
        "        torch.tensor(token_ids),      # Keep token order as is (target sentences)\n",
        "        torch.tensor([EOS_IDX])       # Add end-of-sequence token\n",
        "    ))\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func"
      ],
      "metadata": {
        "id": "wWWuIbkn7TzI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define text transformations"
      ],
      "metadata": {
        "id": "_vrQvyBouRHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flip = True\n",
        "text_transform = {\n",
        "    SRC_LANGUAGE: sequential_transforms(\n",
        "        lambda x: vocab_transform[SRC_LANGUAGE](token_transform[SRC_LANGUAGE](x)),\n",
        "        tensor_transform_s\n",
        "    ),\n",
        "    TGT_LANGUAGE: sequential_transforms(\n",
        "        lambda x: vocab_transform[TGT_LANGUAGE](token_transform[TGT_LANGUAGE](x)),\n",
        "        tensor_transform_t\n",
        "    )\n",
        "}\n"
      ],
      "metadata": {
        "id": "XGg-EdlxuKmZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collate_fn\n",
        "  برای آماده‌سازی یک دسته  از داده‌های ورودی برای مدل استفاده می‌شود. این\n",
        "تابع داده‌های خام را به توکن‌های عددی تبدیل می‌کند، آن‌ها را به طول‌های برابر پر می‌کند ، و سپس آن‌ها را به دستگاهی که مدل روی آن اجرا می‌شود  ارسال می‌کند."
      ],
      "metadata": {
        "id": "yZCixk78qw3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collate function to pad and batch the data\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    # Pad sequences to the same length\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "\n",
        "    print(f\"src_batch in collate_fn: {src_batch.size()}\")\n",
        "    print(f\"tgt_batch in collate_fn: {tgt_batch.size()}\")\n",
        "\n",
        "    return src_batch.to(device), tgt_batch.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "VbZCLS0erXW9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create DataLoader\n",
        "def get_translation_dataloaders(batch_size=8):\n",
        "\n",
        "    # Sort by length of the source sentence for efficiency\n",
        "    sorted_traindataset = sorted(train_dataset, key=lambda x: len(x[0].split()))\n",
        "    sorted_validdataset = sorted(valid_dataset, key=lambda x: len(x[0].split()))\n",
        "    sorted_testdataset = sorted(test_dataset, key=lambda x: len(x[0].split()))\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataloader = DataLoader(\n",
        "        sorted_traindataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=True\n",
        "    )\n",
        "    valid_dataloader = DataLoader(\n",
        "        sorted_validdataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=True\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        sorted_testdataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    return train_dataloader,valid_dataloader,test_dataloader\n",
        "train_dataloader,valid_dataloader,test_dataloader = get_translation_dataloaders(batch_size=4)"
      ],
      "metadata": {
        "id": "x9xm2pPoruLp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation model"
      ],
      "metadata": {
        "id": "72lo_ER3UNT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Word2Vec model for persian"
      ],
      "metadata": {
        "id": "6Hf-DWf5dXRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "word2vec_model = gensim.models.Word2Vec.load('/content/word2vec_persian.model')\n",
        "\n",
        "# Get vocabulary size and embedding dimension\n",
        "vocab_size = fa_vocab_size\n",
        "embedding_dim = word2vec_model.vector_size\n",
        "\n",
        "# Initialize embedding matrix with random values\n",
        "embedding_matrix = np.random.uniform(-0.1, 0.1, (vocab_size, embedding_dim))\n",
        "\n",
        "# Get the vocabulary from your vocab_transform dictionary\n",
        "vocab = vocab_transform['fa'].get_itos() # Assuming 'fa' is the key for your Persian vocabulary\n",
        "\n",
        "# Fill embedding matrix with Word2Vec vectors for words in the vocabulary\n",
        "for i, word in enumerate(vocab):\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]\n",
        "\n",
        "# Convert to torch tensor\n",
        "embedding_matrix_fa = torch.tensor(embedding_matrix, dtype=torch.float).to(device)\n",
        "print(embedding_matrix_fa.shape)\n"
      ],
      "metadata": {
        "id": "VTX9PHDtHGfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d9e35a-d3ac-46c5-e9d1-f175d99fb2e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19855, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Word2Vec model for english"
      ],
      "metadata": {
        "id": "GBL-RuVKdfIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load Word2Vec model for English\n",
        "word2vec_model_en = gensim.models.Word2Vec.load('/content/word2vec_english.model')\n",
        "\n",
        "# Get vocabulary size and embedding dimension for English\n",
        "vocab_size_en = en_vocab_size\n",
        "embedding_dim_en = word2vec_model_en.vector_size\n",
        "\n",
        "# Initialize embedding matrix with random values for English\n",
        "embedding_matrix_en = np.random.uniform(-0.1, 0.1, (vocab_size_en, embedding_dim_en))\n",
        "\n",
        "# Get the vocabulary from your vocab_transform dictionary for English\n",
        "vocab_en = vocab_transform['en'].get_itos()\n",
        "\n",
        "# Fill embedding matrix with Word2Vec vectors for words in the English vocabulary\n",
        "for i, word in enumerate(vocab_en):\n",
        "    if word in word2vec_model_en.wv:\n",
        "        embedding_matrix_en[i] = word2vec_model_en.wv[word]\n",
        "\n",
        "# Convert to torch tensor\n",
        "embedding_matrix_en = torch.tensor(embedding_matrix_en, dtype=torch.float).to(device)\n",
        "print(embedding_matrix_en.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAd2uh0fdayX",
        "outputId": "5eef84f4-5637-4df0-a9f7-2ffd0fa120aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16059, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hid_dim, n_layers, dropout_prob):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define the embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_len, emb_dim)\n",
        "\n",
        "        # Define the LSTM layer\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hid_dim,\n",
        "            num_layers=n_layers,\n",
        "            dropout=dropout_prob,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Store n_layers, hid_dim, and device as instance attributes\n",
        "        self.num_layers = n_layers\n",
        "        self.hidden_size = hid_dim\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        # Get word embeddings for the input batch\n",
        "        embedded = self.embedding(input_batch)  # shape: (batch_size, seq_len, emb_dim)\n",
        "\n",
        "        # Pass through the LSTM\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "91IRQne3wgZd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # Define the embedding layer\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        # Define the LSTM layer\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hid_dim,\n",
        "            num_layers=n_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Define a fully connected layer to output predictions\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        # Define a dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # Pass the input token through the embedding layer\n",
        "        embedded = self.embedding(input)  # shape: (batch_size, emb_dim)\n",
        "\n",
        "        # Apply dropout on embedded input\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # Pass the embedded input and previous hidden, cell states through the LSTM\n",
        "        output, (hidden, cell) = self.rnn(embedded.unsqueeze(1), (hidden, cell))  # unsqueeze to match LSTM input shape\n",
        "\n",
        "        # Convert the hidden state to the output space using a fully connected layer\n",
        "        prediction = self.fc_out(output.squeeze(1))  # shape: (batch_size, output_dim)\n",
        "\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "GuZ-2ek-0SSj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,encoder, decoder, device, trg_vocab):\n",
        "      super().__init__()\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.device = device\n",
        "      self.trg_vocab = trg_vocab\n",
        "      self.trg_vocab_size = len(trg_vocab) # Add this line to store the vocabulary size\n",
        "\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = trg.size(0)  # Batch-first ensures batch_size comes first\n",
        "        trg_len = trg.size(1)    # trg shape is (batch_size, trg_seq_len)\n",
        "        trg_vocab_size = self.decoder.output_dim  # Vocabulary size of the decoder\n",
        "\n",
        "        # Tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # Pass the source sequence through the encoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # Initial input to the decoder is the <sos> token for all batches\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # Pass the input, hidden, and cell state to the decoder\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            # Store the output\n",
        "            outputs[:, t, :] = output\n",
        "\n",
        "            # Decide whether to use teacher forcing\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            # Get the highest probability prediction\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            # Decide the next input: ground truth or prediction\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "4fPwYOcEBtAE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 300\n",
        "hid_dim = 300\n",
        "n_layers = 3\n",
        "dropout_prob= 0.2\n",
        "encoder = Encoder(en_vocab_size, emb_dim, hid_dim, n_layers, dropout_prob)\n",
        "output_dim = fa_vocab_size\n",
        "decoder = Decoder(output_dim, emb_dim, hid_dim, n_layers, dropout_prob)\n",
        "trg_vocab = vocab_transform['fa']\n",
        "model = Seq2Seq(encoder, decoder, device, trg_vocab).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "BMkuU2GwoyYP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation"
      ],
      "metadata": {
        "id": "r4DyfuaxPGeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "PAD_IDX = 1  # Change this according to your setup\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "def compute_loss(outputs, trg):\n",
        "    \"\"\"\n",
        "    Compute the loss for the Seq2Seq model.\n",
        "\n",
        "    Args:\n",
        "    outputs: Predicted logits from the model, shape (trg_len, batch_size, trg_vocab_size)\n",
        "    trg: Ground truth target sequence, shape (trg_len, batch_size)\n",
        "    trg_vocab_size: Size of the target vocabulary\n",
        "\n",
        "    Returns:\n",
        "    loss: Computed loss value\n",
        "    \"\"\"\n",
        "    # Flatten outputs and targets\n",
        "    outputs = outputs.view(-1, outputs.shape[-1])  # (batch_size * trg_len, trg_vocab_size)\n",
        "    print(\"Output shape:\", outputs.shape)\n",
        "    trg = trg.view(-1)  # (batch_size * trg_len)\n",
        "    print(\"Target shape:\", trg.shape)\n",
        "    return criterion(outputs, trg)"
      ],
      "metadata": {
        "id": "xnIU-ACwvaGP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_eng(seq_en):\n",
        "    return \" \".join([vocab_transform['en'].get_itos()[index.item()] for index in seq_en])\n",
        "\n",
        "def index_to_german(seq_de):\n",
        "    return \" \".join([vocab_transform['de'].get_itos()[index.item()] for index in seq_de])"
      ],
      "metadata": {
        "id": "YRMw48SnzXCo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model, iterator, optimizer, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    train_iterator = tqdm(iterator, desc=\"Training\", leave=False)\n",
        "\n",
        "    for i, (src, trg) in enumerate(train_iterator):\n",
        "        # Move data to device (e.g., GPU if available)\n",
        "        src, trg = src.to(model.device), trg.to(model.device)\n",
        "        print(f\"src : {src.size()}\")\n",
        "        print(f\"trg : {trg.size()}\")\n",
        "        # Initialize hidden and cell states with correct batch size\n",
        "        batch_size = src.size(0)\n",
        "        hidden, cell = model.encoder.init_hidden(batch_size)\n",
        "        print(\"Input batch size:\", src.size(0))\n",
        "        print(\"Hidden state shape:\", hidden.size())\n",
        "        print(\"Cell state shape:\", cell.size())\n",
        "        # Output prediction from the model\n",
        "        output = model(src, trg, teacher_forcing_ratio=0.5)\n",
        "\n",
        "        # Adjust dimensions for computing loss\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)  # Flatten (trg_len-1) * batch_size * trg_vocab_size\n",
        "        print(\"Output shape:\", output.shape)\n",
        "        trg = trg[1:].view(-1)  # Flatten (trg_len-1) * batch_size\n",
        "        print(\"Target shape:\", trg.shape)\n",
        "\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = compute_loss(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients to avoid exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # Step the optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the loss\n",
        "        train_iterator.set_postfix(loss=loss.item())\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "U0_OuZuYC-p9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    valid_iterator = tqdm(iterator, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (src, trg) in enumerate(valid_iterator):\n",
        "            # Move data to device\n",
        "            src, trg = src.to(model.device), trg.to(model.device)\n",
        "\n",
        "            # Initialize hidden and cell states with correct batch size\n",
        "            batch_size = src.size(0)  # Changed from src.size(1) to src.size(0)\n",
        "            hidden, cell = model.encoder.init_hidden(batch_size)\n",
        "            print(\"Input batch size:\", src.size(0))\n",
        "            print(\"Hidden state shape:\", hidden.size())\n",
        "            print(\"Cell state shape:\", cell.size())\n",
        "            # Output prediction from the model\n",
        "            output = model(src, trg, teacher_forcing_ratio=0)  # No teacher forcing in evaluation\n",
        "\n",
        "            # Adjust dimensions for computing loss\n",
        "            output_dim = output.shape[0]\n",
        "            output = output[1:].view(-1, output_dim)  # Flatten (trg_len-1) * batch_size * trg_vocab_size\n",
        "            trg = trg[1:].view(-1)  # Flatten (trg_len-1) * batch_size\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = compute_loss(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "metadata": {
        "id": "JRWUs0P_GkKO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_translation(model, src_sentence, src_vocab, trg_vocab, max_len=50):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Convert src_sentence to tensor\n",
        "        src_tensor = torch.tensor([src_vocab.get_stoi().get(word, UNK_IDX) for word in src_sentence.split()]).unsqueeze(0).to(model.device)\n",
        "\n",
        "        # Pass the source tensor through the encoder\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "        # Initialize the target sequence with the <bos> token\n",
        "        trg_indexes = [trg_vocab.get_stoi()['<bos>']]\n",
        "        trg_tensor = torch.tensor([trg_indexes[0]]).to(model.device)  # Remove extra unsqueeze\n",
        "\n",
        "        batch_size = src_tensor.size(0)\n",
        "\n",
        "        hidden = hidden.reshape(model.decoder.rnn.num_layers, batch_size, model.decoder.rnn.hidden_size)\n",
        "        cell = cell.reshape(model.decoder.rnn.num_layers, batch_size, model.decoder.rnn.hidden_size)\n",
        "\n",
        "        for i in range(max_len):\n",
        "            # Output prediction from the decoder\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "            # Get the most probable token (argmax)\n",
        "            pred_token = output.argmax(1).item()  # .item() added to get scalar value\n",
        "            trg_indexes.append(pred_token)\n",
        "\n",
        "            # Stop if the <eos> token is generated\n",
        "            if pred_token == trg_vocab.get_stoi()['<eos>']:\n",
        "                break\n",
        "\n",
        "            # Prepare the next input for the decoder\n",
        "            trg_tensor = torch.tensor([pred_token]).to(model.device)  # Remove extra unsqueeze\n",
        "\n",
        "        # Convert token indexes to words\n",
        "        trg_tokens = [trg_vocab.get_itos()[i] for i in trg_indexes]\n",
        "\n",
        "        # Remove <bos> and <eos> tokens\n",
        "        trg_tokens = trg_tokens[1:]\n",
        "\n",
        "        return \" \".join(trg_tokens)"
      ],
      "metadata": {
        "id": "LgQpsLAwsoo6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "train_iterator = train_dataloader\n",
        "valid_iterator = valid_dataloader\n",
        "clip = 1\n",
        "epochs = 14\n",
        "tlosses = []\n",
        "vlosses = []\n",
        "\n",
        "# Example source sentences for translation\n",
        "src_sentences = [\"I want to go home.\",\"you should translate this sentence.\",\"how are you?\",\"do you want to eat cake?\"]\n",
        "src_vocab = vocab_transform['en']\n",
        "trg_vocab = vocab_transform['fa']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Train the model for one epoch\n",
        "    translation = generate_translation(model, src_sentences[epoch % 4], src_vocab, trg_vocab)\n",
        "    print(f\"Translation: {translation}\")\n",
        "    train_loss = train(model, train_iterator, optimizer, clip)\n",
        "    tlosses.append(train_loss)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Generate a translation for a sample sentence\n",
        "    print('-' * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k2UQy6h8FI7",
        "outputId": "0219f22f-415b-405d-fa1f-ea7bd4ab83c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation: ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁مخفي ▁نگفتي ▁مخفي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁مخفي ▁نگفتي ▁مخفي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁نگفتي ▁مخفي ▁مخفي ▁نگفتي ▁نگفتي ▁مخفي ▁نگفتي\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/13500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 1/13500 [00:00<1:56:24,  1.93it/s, loss=9.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 2/13500 [00:01<2:04:33,  1.81it/s, loss=9.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 3/13500 [00:01<2:04:00,  1.81it/s, loss=9.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 4/13500 [00:02<2:09:50,  1.73it/s, loss=9.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 5/13500 [00:02<2:13:38,  1.68it/s, loss=9.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 17])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 17])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([51, 19855])\n",
            "Target shape: torch.Size([51])\n",
            "Output shape: torch.Size([51, 19855])\n",
            "Target shape: torch.Size([51])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 6/13500 [00:04<3:10:33,  1.18it/s, loss=9.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 7/13500 [00:04<2:52:49,  1.30it/s, loss=9.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 8/13500 [00:05<2:35:23,  1.45it/s, loss=9.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 9/13500 [00:06<2:36:13,  1.44it/s, loss=9.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 10/13500 [00:06<2:36:38,  1.44it/s, loss=9.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 11/13500 [00:07<2:31:15,  1.49it/s, loss=9.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 12/13500 [00:08<2:37:37,  1.43it/s, loss=9.87]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 13/13500 [00:08<2:38:57,  1.41it/s, loss=9.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 14/13500 [00:09<2:58:44,  1.26it/s, loss=9.87]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 15/13500 [00:10<2:46:36,  1.35it/s, loss=9.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 16/13500 [00:11<2:34:52,  1.45it/s, loss=9.85]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 11])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 11])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 17/13500 [00:12<2:55:00,  1.28it/s, loss=9.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 18/13500 [00:12<2:47:01,  1.35it/s, loss=9.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 19/13500 [00:13<2:25:16,  1.55it/s, loss=9.83]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 20/13500 [00:13<2:08:37,  1.75it/s, loss=9.84]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 21/13500 [00:14<2:05:28,  1.79it/s, loss=9.83]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 22/13500 [00:14<2:00:00,  1.87it/s, loss=9.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 23/13500 [00:15<1:59:58,  1.87it/s, loss=9.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 24/13500 [00:15<2:00:31,  1.86it/s, loss=9.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 25/13500 [00:16<2:04:48,  1.80it/s, loss=9.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 26/13500 [00:16<2:12:14,  1.70it/s, loss=9.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 27/13500 [00:17<2:07:55,  1.76it/s, loss=9.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 28/13500 [00:18<2:13:33,  1.68it/s, loss=9.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 29/13500 [00:18<2:04:02,  1.81it/s, loss=9.71]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 30/13500 [00:19<2:05:05,  1.79it/s, loss=9.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 31/13500 [00:19<1:59:30,  1.88it/s, loss=9.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 32/13500 [00:20<1:56:19,  1.93it/s, loss=9.56]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 33/13500 [00:20<1:58:37,  1.89it/s, loss=9.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 34/13500 [00:20<1:51:16,  2.02it/s, loss=9.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 35/13500 [00:21<1:47:37,  2.09it/s, loss=9.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 36/13500 [00:21<1:46:12,  2.11it/s, loss=9.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 37/13500 [00:22<1:51:09,  2.02it/s, loss=9.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 38/13500 [00:22<1:50:58,  2.02it/s, loss=9.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 39/13500 [00:23<2:12:01,  1.70it/s, loss=9.31]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 40/13500 [00:24<2:11:14,  1.71it/s, loss=9.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 41/13500 [00:24<2:12:40,  1.69it/s, loss=9.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 42/13500 [00:25<2:14:08,  1.67it/s, loss=8.84]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 43/13500 [00:26<2:12:18,  1.70it/s, loss=8.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 44/13500 [00:26<2:12:00,  1.70it/s, loss=8.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 45/13500 [00:27<2:11:35,  1.70it/s, loss=8.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 46/13500 [00:27<2:15:34,  1.65it/s, loss=8.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 47/13500 [00:28<2:07:26,  1.76it/s, loss=8.54]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 48/13500 [00:28<1:57:44,  1.90it/s, loss=8.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 49/13500 [00:29<1:58:54,  1.89it/s, loss=8.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 50/13500 [00:30<2:07:35,  1.76it/s, loss=8.07]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 51/13500 [00:30<2:07:41,  1.76it/s, loss=7.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 52/13500 [00:31<2:11:10,  1.71it/s, loss=8.26]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 53/13500 [00:31<2:11:56,  1.70it/s, loss=7.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 54/13500 [00:32<2:16:36,  1.64it/s, loss=7.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 55/13500 [00:33<2:11:21,  1.71it/s, loss=7.54]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 56/13500 [00:33<2:05:14,  1.79it/s, loss=7.62]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 57/13500 [00:34<2:03:24,  1.82it/s, loss=7.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 58/13500 [00:34<1:59:33,  1.87it/s, loss=7.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 59/13500 [00:35<1:57:07,  1.91it/s, loss=7.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 60/13500 [00:35<1:52:49,  1.99it/s, loss=7.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 61/13500 [00:35<1:50:58,  2.02it/s, loss=7.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 62/13500 [00:36<1:44:44,  2.14it/s, loss=7.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 63/13500 [00:36<1:45:21,  2.13it/s, loss=7.58]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 64/13500 [00:37<1:52:37,  1.99it/s, loss=7.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 65/13500 [00:37<1:56:59,  1.91it/s, loss=7.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 66/13500 [00:38<2:12:00,  1.70it/s, loss=8.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 67/13500 [00:39<2:19:47,  1.60it/s, loss=7.26]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 68/13500 [00:40<2:18:23,  1.62it/s, loss=7.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 3])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 3])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([9, 19855])\n",
            "Target shape: torch.Size([9])\n",
            "Output shape: torch.Size([9, 19855])\n",
            "Target shape: torch.Size([9])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 69/13500 [00:40<2:07:35,  1.75it/s, loss=6.55]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 70/13500 [00:41<2:06:35,  1.77it/s, loss=7.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 3])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 3])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([9, 19855])\n",
            "Target shape: torch.Size([9])\n",
            "Output shape: torch.Size([9, 19855])\n",
            "Target shape: torch.Size([9])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 71/13500 [00:41<1:59:44,  1.87it/s, loss=6.65]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 72/13500 [00:41<1:53:16,  1.98it/s, loss=6.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 73/13500 [00:42<1:56:16,  1.92it/s, loss=7.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 74/13500 [00:42<1:49:29,  2.04it/s, loss=6.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 75/13500 [00:43<1:48:26,  2.06it/s, loss=6.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 76/13500 [00:43<1:52:59,  1.98it/s, loss=7.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 77/13500 [00:44<2:03:00,  1.82it/s, loss=6.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 78/13500 [00:45<2:51:03,  1.31it/s, loss=7.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 79/13500 [00:47<3:17:07,  1.13it/s, loss=8.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 80/13500 [00:48<3:31:07,  1.06it/s, loss=6.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 81/13500 [00:49<3:36:03,  1.04it/s, loss=6.66]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 82/13500 [00:50<3:39:40,  1.02it/s, loss=7.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 83/13500 [00:50<3:19:56,  1.12it/s, loss=7.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 84/13500 [00:51<2:54:03,  1.28it/s, loss=6.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 85/13500 [00:52<2:48:50,  1.32it/s, loss=7.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 86/13500 [00:52<2:45:04,  1.35it/s, loss=6.72]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 11])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 11])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 87/13500 [00:53<3:00:28,  1.24it/s, loss=7.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 88/13500 [00:54<2:51:22,  1.30it/s, loss=6.84]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 89/13500 [00:54<2:38:07,  1.41it/s, loss=6.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 90/13500 [00:55<2:31:44,  1.47it/s, loss=6.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 91/13500 [00:56<2:29:58,  1.49it/s, loss=6.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 92/13500 [00:56<2:17:38,  1.62it/s, loss=6.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 93/13500 [00:57<2:16:35,  1.64it/s, loss=7.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 94/13500 [00:57<2:11:45,  1.70it/s, loss=6.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 95/13500 [00:58<2:06:42,  1.76it/s, loss=7.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 96/13500 [00:58<2:04:31,  1.79it/s, loss=6.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 97/13500 [00:59<2:16:06,  1.64it/s, loss=6.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 98/13500 [01:00<2:17:11,  1.63it/s, loss=6.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 99/13500 [01:00<2:11:43,  1.70it/s, loss=6.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 100/13500 [01:01<2:03:10,  1.81it/s, loss=6.12]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 101/13500 [01:01<1:55:29,  1.93it/s, loss=6.65]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 102/13500 [01:02<1:52:43,  1.98it/s, loss=5.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 103/13500 [01:02<1:54:09,  1.96it/s, loss=6.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 104/13500 [01:03<1:52:24,  1.99it/s, loss=6.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 105/13500 [01:03<1:50:04,  2.03it/s, loss=6.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 106/13500 [01:04<1:51:03,  2.01it/s, loss=6.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 107/13500 [01:04<1:59:29,  1.87it/s, loss=6.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 108/13500 [01:05<2:01:54,  1.83it/s, loss=6.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 109/13500 [01:05<2:04:49,  1.79it/s, loss=6.55]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 110/13500 [01:06<2:02:02,  1.83it/s, loss=5.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 14])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 14])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([42, 19855])\n",
            "Target shape: torch.Size([42])\n",
            "Output shape: torch.Size([42, 19855])\n",
            "Target shape: torch.Size([42])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 111/13500 [01:07<2:48:22,  1.33it/s, loss=8.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 10])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 10])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 112/13500 [01:08<3:05:08,  1.21it/s, loss=7.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 113/13500 [01:09<2:49:39,  1.32it/s, loss=5.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 114/13500 [01:10<2:55:33,  1.27it/s, loss=6.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 115/13500 [01:10<2:38:52,  1.40it/s, loss=5.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 116/13500 [01:11<2:25:37,  1.53it/s, loss=5.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 117/13500 [01:11<2:17:12,  1.63it/s, loss=5.78]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 118/13500 [01:12<2:05:33,  1.78it/s, loss=6.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 119/13500 [01:12<2:01:12,  1.84it/s, loss=6.64]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 120/13500 [01:13<2:01:09,  1.84it/s, loss=7.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 121/13500 [01:13<2:00:58,  1.84it/s, loss=6.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 122/13500 [01:14<2:00:56,  1.84it/s, loss=6.59]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 123/13500 [01:14<2:06:02,  1.77it/s, loss=5.85]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 124/13500 [01:15<2:16:25,  1.63it/s, loss=7.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 125/13500 [01:16<2:16:18,  1.64it/s, loss=6.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 126/13500 [01:17<2:31:45,  1.47it/s, loss=6.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 127/13500 [01:18<2:49:45,  1.31it/s, loss=6.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 128/13500 [01:18<2:56:46,  1.26it/s, loss=6.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 129/13500 [01:19<2:43:27,  1.36it/s, loss=5.87]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 11])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 11])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 130/13500 [01:22<5:27:14,  1.47s/it, loss=7.96]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 131/13500 [01:24<6:13:40,  1.68s/it, loss=5.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 132/13500 [01:25<5:22:26,  1.45s/it, loss=6.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 133/13500 [01:26<4:20:01,  1.17s/it, loss=5.35]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 134/13500 [01:26<3:36:40,  1.03it/s, loss=6.66]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 135/13500 [01:27<3:12:02,  1.16it/s, loss=7.64]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 136/13500 [01:27<2:48:59,  1.32it/s, loss=6.65]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 137/13500 [01:28<2:40:08,  1.39it/s, loss=6.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 138/13500 [01:29<2:29:42,  1.49it/s, loss=7.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 139/13500 [01:29<2:22:52,  1.56it/s, loss=6.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 140/13500 [01:30<2:58:23,  1.25it/s, loss=6.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 141/13500 [01:32<3:21:52,  1.10it/s, loss=6.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 142/13500 [01:32<2:53:57,  1.28it/s, loss=5.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 143/13500 [01:33<2:50:17,  1.31it/s, loss=6.55]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 144/13500 [01:33<2:33:04,  1.45it/s, loss=5.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 145/13500 [01:34<2:26:30,  1.52it/s, loss=6.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 146/13500 [01:35<2:30:59,  1.47it/s, loss=7.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 147/13500 [01:35<2:39:41,  1.39it/s, loss=5.71]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 148/13500 [01:36<2:35:19,  1.43it/s, loss=6.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 149/13500 [01:37<2:25:56,  1.52it/s, loss=5.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 150/13500 [01:37<2:35:07,  1.43it/s, loss=7.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 151/13500 [01:38<2:30:14,  1.48it/s, loss=5.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 17])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 17])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([51, 19855])\n",
            "Target shape: torch.Size([51])\n",
            "Output shape: torch.Size([51, 19855])\n",
            "Target shape: torch.Size([51])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 152/13500 [01:39<3:23:35,  1.09it/s, loss=5.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 153/13500 [01:40<2:54:12,  1.28it/s, loss=5.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 154/13500 [01:40<2:35:10,  1.43it/s, loss=5.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 155/13500 [01:41<2:19:33,  1.59it/s, loss=5.54]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 156/13500 [01:41<2:14:55,  1.65it/s, loss=6.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 157/13500 [01:42<2:15:21,  1.64it/s, loss=7.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 158/13500 [01:43<2:14:24,  1.65it/s, loss=7.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 159/13500 [01:44<2:30:43,  1.48it/s, loss=6.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 160/13500 [01:44<2:29:12,  1.49it/s, loss=6.16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 161/13500 [01:45<2:29:00,  1.49it/s, loss=7.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 162/13500 [01:45<2:19:00,  1.60it/s, loss=7.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 163/13500 [01:46<2:09:19,  1.72it/s, loss=4.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 164/13500 [01:46<2:06:23,  1.76it/s, loss=5.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 165/13500 [01:47<1:58:49,  1.87it/s, loss=6.78]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 166/13500 [01:47<1:58:18,  1.88it/s, loss=6.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 167/13500 [01:48<1:59:37,  1.86it/s, loss=6.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 168/13500 [01:49<2:11:10,  1.69it/s, loss=6.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 169/13500 [01:49<2:18:53,  1.60it/s, loss=6.65]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 170/13500 [01:50<2:21:25,  1.57it/s, loss=6.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 171/13500 [01:51<2:19:19,  1.59it/s, loss=5.96]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 172/13500 [01:51<2:20:29,  1.58it/s, loss=6.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 173/13500 [01:52<2:22:46,  1.56it/s, loss=5.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 174/13500 [01:53<2:21:41,  1.57it/s, loss=6.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 175/13500 [01:53<2:36:38,  1.42it/s, loss=7.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 176/13500 [01:54<2:48:08,  1.32it/s, loss=6.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 177/13500 [01:55<2:31:58,  1.46it/s, loss=6.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 178/13500 [01:56<2:36:04,  1.42it/s, loss=6.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 179/13500 [01:56<2:27:07,  1.51it/s, loss=6.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 180/13500 [01:57<2:13:54,  1.66it/s, loss=5.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 181/13500 [01:57<2:06:30,  1.75it/s, loss=6.85]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 182/13500 [01:58<1:59:35,  1.86it/s, loss=6.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 183/13500 [01:58<1:58:12,  1.88it/s, loss=6.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 184/13500 [01:59<1:58:00,  1.88it/s, loss=6.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 185/13500 [01:59<2:01:53,  1.82it/s, loss=5.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 186/13500 [02:00<1:57:20,  1.89it/s, loss=5.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 187/13500 [02:00<1:59:22,  1.86it/s, loss=6.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 188/13500 [02:01<1:56:58,  1.90it/s, loss=4.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 189/13500 [02:01<2:03:30,  1.80it/s, loss=7.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 190/13500 [02:02<1:55:31,  1.92it/s, loss=6.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 191/13500 [02:02<1:59:54,  1.85it/s, loss=6.59]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 192/13500 [02:03<2:05:17,  1.77it/s, loss=6.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 193/13500 [02:04<2:19:05,  1.59it/s, loss=6.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 194/13500 [02:04<2:17:48,  1.61it/s, loss=6.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 4])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 4])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n",
            "Output shape: torch.Size([12, 19855])\n",
            "Target shape: torch.Size([12])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 195/13500 [02:05<2:16:37,  1.62it/s, loss=5.94]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 10])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 10])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 196/13500 [02:06<2:37:44,  1.41it/s, loss=7.62]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 4])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 4])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 197/13500 [02:07<2:35:38,  1.42it/s, loss=6.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 198/13500 [02:07<2:39:54,  1.39it/s, loss=7.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 199/13500 [02:08<2:48:15,  1.32it/s, loss=8.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 10])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 10])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 200/13500 [02:09<2:57:14,  1.25it/s, loss=8.55]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 201/13500 [02:10<2:46:51,  1.33it/s, loss=7.85]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 202/13500 [02:10<2:36:08,  1.42it/s, loss=7.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 203/13500 [02:11<2:31:44,  1.46it/s, loss=7.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 204/13500 [02:12<2:44:17,  1.35it/s, loss=6.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 205/13500 [02:13<2:41:08,  1.38it/s, loss=6.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 206/13500 [02:13<2:55:53,  1.26it/s, loss=7.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 10])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 10])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 207/13500 [02:14<2:49:11,  1.31it/s, loss=6.58]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 208/13500 [02:15<2:41:18,  1.37it/s, loss=6.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 209/13500 [02:15<2:38:33,  1.40it/s, loss=6.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 210/13500 [02:16<2:41:02,  1.38it/s, loss=7.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 211/13500 [02:17<2:37:45,  1.40it/s, loss=7.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 212/13500 [02:18<2:35:25,  1.42it/s, loss=7.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 213/13500 [02:18<2:32:05,  1.46it/s, loss=7.55]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 214/13500 [02:19<2:41:46,  1.37it/s, loss=7.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 215/13500 [02:20<2:53:00,  1.28it/s, loss=6.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 216/13500 [02:21<3:05:54,  1.19it/s, loss=6.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 217/13500 [02:22<2:57:34,  1.25it/s, loss=6.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 218/13500 [02:24<4:15:07,  1.15s/it, loss=7.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 219/13500 [02:27<6:16:41,  1.70s/it, loss=6.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 220/13500 [02:28<6:06:41,  1.66s/it, loss=6.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 221/13500 [02:29<5:22:39,  1.46s/it, loss=7.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 222/13500 [02:30<5:03:08,  1.37s/it, loss=6.78]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 223/13500 [02:31<4:21:09,  1.18s/it, loss=8.07]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 10])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 10])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 224/13500 [02:32<3:43:45,  1.01s/it, loss=6.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 225/13500 [02:32<3:21:08,  1.10it/s, loss=7.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 10])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 10])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 226/13500 [02:33<3:14:48,  1.14it/s, loss=7.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 227/13500 [02:34<2:56:45,  1.25it/s, loss=6.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 12])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 12])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([36, 19855])\n",
            "Target shape: torch.Size([36])\n",
            "Output shape: torch.Size([36, 19855])\n",
            "Target shape: torch.Size([36])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 228/13500 [02:35<3:25:15,  1.08it/s, loss=8.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 229/13500 [02:36<3:18:50,  1.11it/s, loss=6.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 230/13500 [02:37<3:10:44,  1.16it/s, loss=7.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 231/13500 [02:37<3:09:27,  1.17it/s, loss=6.44]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 232/13500 [02:38<3:06:37,  1.18it/s, loss=7.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 233/13500 [02:39<2:57:00,  1.25it/s, loss=6.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 234/13500 [02:40<2:58:54,  1.24it/s, loss=6.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 235/13500 [02:41<3:04:47,  1.20it/s, loss=7.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 236/13500 [02:42<3:05:27,  1.19it/s, loss=7.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 237/13500 [02:42<3:00:18,  1.23it/s, loss=6.83]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 238/13500 [02:43<2:45:34,  1.33it/s, loss=7.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 239/13500 [02:44<2:41:19,  1.37it/s, loss=6.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 240/13500 [02:44<2:45:39,  1.33it/s, loss=7.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 241/13500 [02:45<2:50:02,  1.30it/s, loss=7.63]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 242/13500 [02:46<2:50:22,  1.30it/s, loss=6.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 243/13500 [02:47<2:58:59,  1.23it/s, loss=7.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 244/13500 [02:47<2:45:44,  1.33it/s, loss=7.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 245/13500 [02:48<2:39:21,  1.39it/s, loss=6.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 246/13500 [02:49<3:05:34,  1.19it/s, loss=6.62]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 247/13500 [02:50<3:07:50,  1.18it/s, loss=6.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 248/13500 [02:51<3:10:13,  1.16it/s, loss=6.96]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 249/13500 [02:52<3:06:38,  1.18it/s, loss=6.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 250/13500 [02:53<3:04:14,  1.20it/s, loss=7.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 251/13500 [02:53<3:00:02,  1.23it/s, loss=7.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 252/13500 [02:54<2:55:01,  1.26it/s, loss=7.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 253/13500 [02:55<2:53:22,  1.27it/s, loss=7.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 5])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 5])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 254/13500 [02:56<2:46:47,  1.32it/s, loss=7.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 255/13500 [02:56<2:44:55,  1.34it/s, loss=7.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 256/13500 [02:57<2:45:33,  1.33it/s, loss=6.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 257/13500 [02:58<2:48:38,  1.31it/s, loss=6.16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 258/13500 [02:59<2:51:58,  1.28it/s, loss=6.71]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 259/13500 [03:00<2:54:53,  1.26it/s, loss=7.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 260/13500 [03:00<2:58:40,  1.24it/s, loss=7.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 261/13500 [03:01<2:54:48,  1.26it/s, loss=7.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 10])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 10])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 262/13500 [03:02<2:58:24,  1.24it/s, loss=8.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 263/13500 [03:03<3:06:29,  1.18it/s, loss=7.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 264/13500 [03:04<3:23:12,  1.09it/s, loss=7.33]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 265/13500 [03:05<3:20:27,  1.10it/s, loss=6.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 266/13500 [03:06<3:36:32,  1.02it/s, loss=7.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 267/13500 [03:07<3:39:49,  1.00it/s, loss=7.71]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 268/13500 [03:08<3:20:11,  1.10it/s, loss=7.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 269/13500 [03:08<3:06:46,  1.18it/s, loss=7.16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 11])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 11])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 270/13500 [03:10<3:22:30,  1.09it/s, loss=7.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 271/13500 [03:10<2:59:24,  1.23it/s, loss=7.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 272/13500 [03:11<2:44:38,  1.34it/s, loss=6.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 273/13500 [03:11<2:39:29,  1.38it/s, loss=7.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 274/13500 [03:12<2:53:05,  1.27it/s, loss=6.72]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 275/13500 [03:13<2:54:32,  1.26it/s, loss=6.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 276/13500 [03:14<2:46:01,  1.33it/s, loss=6.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 277/13500 [03:15<2:50:18,  1.29it/s, loss=7.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 278/13500 [03:16<3:11:16,  1.15it/s, loss=7.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 279/13500 [03:18<4:36:31,  1.25s/it, loss=6.72]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 280/13500 [03:20<5:20:10,  1.45s/it, loss=7.26]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 281/13500 [03:21<5:37:38,  1.53s/it, loss=6.55]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 282/13500 [03:23<5:18:11,  1.44s/it, loss=7.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 283/13500 [03:24<4:49:27,  1.31s/it, loss=6.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 284/13500 [03:25<4:17:16,  1.17s/it, loss=6.66]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 285/13500 [03:26<4:05:13,  1.11s/it, loss=7.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 286/13500 [03:26<3:51:33,  1.05s/it, loss=6.62]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 287/13500 [03:27<3:42:19,  1.01s/it, loss=6.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 288/13500 [03:29<4:02:50,  1.10s/it, loss=6.94]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 289/13500 [03:30<3:55:18,  1.07s/it, loss=7.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 290/13500 [03:30<3:25:42,  1.07it/s, loss=6.87]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 291/13500 [03:31<3:03:40,  1.20it/s, loss=6.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 292/13500 [03:32<2:49:08,  1.30it/s, loss=7.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 293/13500 [03:32<2:55:48,  1.25it/s, loss=7.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 11])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 11])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n",
            "Output shape: torch.Size([33, 19855])\n",
            "Target shape: torch.Size([33])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 294/13500 [03:34<3:17:30,  1.11it/s, loss=7.78]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 10])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 10])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n",
            "Output shape: torch.Size([30, 19855])\n",
            "Target shape: torch.Size([30])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 295/13500 [03:35<3:39:49,  1.00it/s, loss=7.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 296/13500 [03:36<3:38:37,  1.01it/s, loss=7.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 297/13500 [03:36<3:23:43,  1.08it/s, loss=6.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 298/13500 [03:37<3:05:30,  1.19it/s, loss=6.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 299/13500 [03:38<2:52:20,  1.28it/s, loss=6.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 300/13500 [03:39<2:50:12,  1.29it/s, loss=6.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 301/13500 [03:40<3:10:08,  1.16it/s, loss=6.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 302/13500 [03:41<3:29:03,  1.05it/s, loss=7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 9])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 9])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n",
            "Output shape: torch.Size([27, 19855])\n",
            "Target shape: torch.Size([27])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 303/13500 [03:42<3:39:09,  1.00it/s, loss=7.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 9])\n",
            "tgt_batch in collate_fn: torch.Size([4, 8])\n",
            "src : torch.Size([4, 9])\n",
            "trg : torch.Size([4, 8])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n",
            "Output shape: torch.Size([24, 19855])\n",
            "Target shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 304/13500 [03:43<3:37:03,  1.01it/s, loss=7.04]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 8])\n",
            "tgt_batch in collate_fn: torch.Size([4, 7])\n",
            "src : torch.Size([4, 8])\n",
            "trg : torch.Size([4, 7])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n",
            "Output shape: torch.Size([21, 19855])\n",
            "Target shape: torch.Size([21])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 305/13500 [03:44<3:26:58,  1.06it/s, loss=6.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 6])\n",
            "tgt_batch in collate_fn: torch.Size([4, 5])\n",
            "src : torch.Size([4, 6])\n",
            "trg : torch.Size([4, 5])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n",
            "Output shape: torch.Size([15, 19855])\n",
            "Target shape: torch.Size([15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|▏         | 306/13500 [03:44<3:17:32,  1.11it/s, loss=6.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch in collate_fn: torch.Size([4, 7])\n",
            "tgt_batch in collate_fn: torch.Size([4, 6])\n",
            "src : torch.Size([4, 7])\n",
            "trg : torch.Size([4, 6])\n",
            "Input batch size: 4\n",
            "Hidden state shape: torch.Size([3, 4, 300])\n",
            "Cell state shape: torch.Size([3, 4, 300])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n",
            "Output shape: torch.Size([18, 19855])\n",
            "Target shape: torch.Size([18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 306/13500 [03:45<3:17:32,  1.11it/s, loss=6.63]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cbz7mR4Yn-zF",
        "S_2S4KYRLLNJ",
        "7yXm8a3cOrjF"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60367ad3c26f40bc9a7ca99b528ec3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2712798c358347c89f979ffd06450bf3",
              "IPY_MODEL_09c8115dd5e0475fbf4c7c39bf89725f",
              "IPY_MODEL_7264731988124b0db16e9bba010633ff"
            ],
            "layout": "IPY_MODEL_3f8ff5003b6e48339788d7c94e7f84b1"
          }
        },
        "2712798c358347c89f979ffd06450bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_676792d4c0de4a3eb4608aaae50dde0e",
            "placeholder": "​",
            "style": "IPY_MODEL_583fa59f4bdc45e99fd4e0b5fb60f991",
            "value": "README.md: 100%"
          }
        },
        "09c8115dd5e0475fbf4c7c39bf89725f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee6d33e94f44ebaaab513f8111e01f0",
            "max": 4395,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed2a2e54bf9e4af1bbeded029bcc850f",
            "value": 4395
          }
        },
        "7264731988124b0db16e9bba010633ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7641edf42be04e92b8d18f40c57998b2",
            "placeholder": "​",
            "style": "IPY_MODEL_7ba86dd3dce24946b0d15a4286d823c1",
            "value": " 4.39k/4.39k [00:00&lt;00:00, 227kB/s]"
          }
        },
        "3f8ff5003b6e48339788d7c94e7f84b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676792d4c0de4a3eb4608aaae50dde0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583fa59f4bdc45e99fd4e0b5fb60f991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee6d33e94f44ebaaab513f8111e01f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2a2e54bf9e4af1bbeded029bcc850f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7641edf42be04e92b8d18f40c57998b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba86dd3dce24946b0d15a4286d823c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68b64518e96946b19a4f2b9acb24d75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07abd35f89b74ce3971fe0c8d8acf5e2",
              "IPY_MODEL_b4023bb5354a41fc963a09a092505822",
              "IPY_MODEL_216bbd5713ad451c822ee3368fd44370"
            ],
            "layout": "IPY_MODEL_2f024a750f9d44b5b468dcdf340d394e"
          }
        },
        "07abd35f89b74ce3971fe0c8d8acf5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df47677ca6c4ad1830da124ea4c3365",
            "placeholder": "​",
            "style": "IPY_MODEL_6092e1d915af468f9800e7f30959f906",
            "value": "parsinlu_translation_en_fa.py: 100%"
          }
        },
        "b4023bb5354a41fc963a09a092505822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3acc7164464644ae9ab8b7bf924b1c",
            "max": 5215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cda6ae5c0f0245a3beac0bbd41b7da92",
            "value": 5215
          }
        },
        "216bbd5713ad451c822ee3368fd44370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22849f9a3d6643729e00559a1de58095",
            "placeholder": "​",
            "style": "IPY_MODEL_d3d5bc169c52484697d5ec9dc94ff37b",
            "value": " 5.21k/5.21k [00:00&lt;00:00, 290kB/s]"
          }
        },
        "2f024a750f9d44b5b468dcdf340d394e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df47677ca6c4ad1830da124ea4c3365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6092e1d915af468f9800e7f30959f906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c3acc7164464644ae9ab8b7bf924b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda6ae5c0f0245a3beac0bbd41b7da92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22849f9a3d6643729e00559a1de58095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d5bc169c52484697d5ec9dc94ff37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c75621b4437a4372bde748a433dd9626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8340ee1ff41244bc8401ba22b654d5c3",
              "IPY_MODEL_55f7e8b09e4f4ea384997ee102cc6db0",
              "IPY_MODEL_6998f094d925466e9575ffda8fd52f97"
            ],
            "layout": "IPY_MODEL_9f9d3368ef644ceba6663550f9909aa1"
          }
        },
        "8340ee1ff41244bc8401ba22b654d5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14af2617c08456999324464cc84bb87",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf9bd3833434b55a0a16f8cfb99a9b1",
            "value": "0000.parquet: 100%"
          }
        },
        "55f7e8b09e4f4ea384997ee102cc6db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e0f091cdf34259958c67770ce07cad",
            "max": 135105167,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1527b9e30cda4b2cbcd040156ce7d381",
            "value": 135105167
          }
        },
        "6998f094d925466e9575ffda8fd52f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05dda08b2cae4b409fca351e19977883",
            "placeholder": "​",
            "style": "IPY_MODEL_ea3ae63b9ce044518eb3229541e4616e",
            "value": " 135M/135M [00:01&lt;00:00, 166MB/s]"
          }
        },
        "9f9d3368ef644ceba6663550f9909aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14af2617c08456999324464cc84bb87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf9bd3833434b55a0a16f8cfb99a9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e0f091cdf34259958c67770ce07cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1527b9e30cda4b2cbcd040156ce7d381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05dda08b2cae4b409fca351e19977883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3ae63b9ce044518eb3229541e4616e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8351df7c6f624b2892e87358bcb92f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6985091be50d426d91009da8de52b038",
              "IPY_MODEL_875947564b8f4a7c98f7e5dfa1222c34",
              "IPY_MODEL_0ecc4bc9efb64204bc87acb85e1edd7c"
            ],
            "layout": "IPY_MODEL_f63677da0dcd4a8d85bbbe9852fd4de9"
          }
        },
        "6985091be50d426d91009da8de52b038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba18a5e4ffb4af48018b8898d45dec1",
            "placeholder": "​",
            "style": "IPY_MODEL_25ebe9545a83410e868f783c88f396f4",
            "value": "0000.parquet: 100%"
          }
        },
        "875947564b8f4a7c98f7e5dfa1222c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ad12e94e8848f39f2bf2152dc1f476",
            "max": 12192942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed382e4926bc477faf34990d7323c763",
            "value": 12192942
          }
        },
        "0ecc4bc9efb64204bc87acb85e1edd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926e71d1736948f99e4be5323ed8f62c",
            "placeholder": "​",
            "style": "IPY_MODEL_9b19459bf8e1440097ef489c9c1f64a6",
            "value": " 12.2M/12.2M [00:00&lt;00:00, 101MB/s]"
          }
        },
        "f63677da0dcd4a8d85bbbe9852fd4de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba18a5e4ffb4af48018b8898d45dec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ebe9545a83410e868f783c88f396f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ad12e94e8848f39f2bf2152dc1f476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed382e4926bc477faf34990d7323c763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "926e71d1736948f99e4be5323ed8f62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b19459bf8e1440097ef489c9c1f64a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2d46912ad9c47f6a6df36ca64bbeb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75ef79547c024b568766375a347f6fd4",
              "IPY_MODEL_2cd971faf2664aab9961f96e80df3fc5",
              "IPY_MODEL_da60603efa914bc78902be738698b816"
            ],
            "layout": "IPY_MODEL_70624d702f24491d9ecc7174fd18ced2"
          }
        },
        "75ef79547c024b568766375a347f6fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb40f7be31e45a8a40bab961aa46f9d",
            "placeholder": "​",
            "style": "IPY_MODEL_cad0794112424eef8afdd00d1aa1cada",
            "value": "parsinlu-repo/validation/0000.parquet: 100%"
          }
        },
        "2cd971faf2664aab9961f96e80df3fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6aeafafc56b4807aeb1bd72c387987d",
            "max": 242476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90e87b3d475c4fd8b4012f8f27ce51c6",
            "value": 242476
          }
        },
        "da60603efa914bc78902be738698b816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b317f0e0d74c3a85a7db17c5c54929",
            "placeholder": "​",
            "style": "IPY_MODEL_0a24f698277e449dac7fcf86e73e6c0d",
            "value": " 242k/242k [00:00&lt;00:00, 8.62MB/s]"
          }
        },
        "70624d702f24491d9ecc7174fd18ced2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb40f7be31e45a8a40bab961aa46f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad0794112424eef8afdd00d1aa1cada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6aeafafc56b4807aeb1bd72c387987d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e87b3d475c4fd8b4012f8f27ce51c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7b317f0e0d74c3a85a7db17c5c54929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a24f698277e449dac7fcf86e73e6c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "653943bf2c624dd8a003fcc37ecc0426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c4215ae641f4e0a8182fed831749dd9",
              "IPY_MODEL_0691772a493d4e91a83acbc9d5db0dcc",
              "IPY_MODEL_746e1e2dae3144c1adf4c663bffac599"
            ],
            "layout": "IPY_MODEL_46dba8783456476ea17bdd6ad56821c7"
          }
        },
        "1c4215ae641f4e0a8182fed831749dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601b32f9b2604524be83e0f1e498aef2",
            "placeholder": "​",
            "style": "IPY_MODEL_9122f8a472434a12b67fe9739367bbf8",
            "value": "Generating train split: 100%"
          }
        },
        "0691772a493d4e91a83acbc9d5db0dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894b9724659a46939873e1a86cc910d6",
            "max": 1621665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4feadb96112545ae8c770f5baea3b560",
            "value": 1621665
          }
        },
        "746e1e2dae3144c1adf4c663bffac599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13540c5874d4cb388a739a6c0cda21b",
            "placeholder": "​",
            "style": "IPY_MODEL_70a04e840892460ea9870215fd63ba28",
            "value": " 1621665/1621665 [00:06&lt;00:00, 458252.64 examples/s]"
          }
        },
        "46dba8783456476ea17bdd6ad56821c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601b32f9b2604524be83e0f1e498aef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9122f8a472434a12b67fe9739367bbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "894b9724659a46939873e1a86cc910d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4feadb96112545ae8c770f5baea3b560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d13540c5874d4cb388a739a6c0cda21b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a04e840892460ea9870215fd63ba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4f4694f93f4b40a90d968171ca531b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a5111503103476eaf9f2cf3be370d61",
              "IPY_MODEL_a7b48bb76bba46dead8196f842621b39",
              "IPY_MODEL_172384085cfc4ff2bb64475917a2f1ef"
            ],
            "layout": "IPY_MODEL_7e4f8016a2f54189bd79438d5a792184"
          }
        },
        "0a5111503103476eaf9f2cf3be370d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9984c5bb92496a8cfa7b46d4f3dac8",
            "placeholder": "​",
            "style": "IPY_MODEL_8252b057178644e58a0833d99f53cb9e",
            "value": "Generating test split: 100%"
          }
        },
        "a7b48bb76bba46dead8196f842621b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c7ff97409546f78bb9ba9c914e670d",
            "max": 48359,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_298821f77c0a4de0bbbaacdbd9ab74f6",
            "value": 48359
          }
        },
        "172384085cfc4ff2bb64475917a2f1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a68b81ee78a042c39f8a77c55d1bbf9c",
            "placeholder": "​",
            "style": "IPY_MODEL_93e0cc221bdd4c8a9b01e53c9e968c05",
            "value": " 48359/48359 [00:00&lt;00:00, 74313.13 examples/s]"
          }
        },
        "7e4f8016a2f54189bd79438d5a792184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9984c5bb92496a8cfa7b46d4f3dac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8252b057178644e58a0833d99f53cb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c7ff97409546f78bb9ba9c914e670d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298821f77c0a4de0bbbaacdbd9ab74f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a68b81ee78a042c39f8a77c55d1bbf9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e0cc221bdd4c8a9b01e53c9e968c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8a72eda82c9403e8975e1994563c687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f63d61b1ed9c435dbaf0d7813d15dd48",
              "IPY_MODEL_0e57ec84daf04ec2aada45c14142ff8a",
              "IPY_MODEL_f58c3967cf944353900a0af28f3844c2"
            ],
            "layout": "IPY_MODEL_60b2e0da790d4891bb37cdf2df5df586"
          }
        },
        "f63d61b1ed9c435dbaf0d7813d15dd48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82dbc1bb964e405196161bc0e001099c",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd464d511fd4cbe8ec4bf21b3a126b1",
            "value": "Generating validation split: 100%"
          }
        },
        "0e57ec84daf04ec2aada45c14142ff8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aae6615de4204e1b8004ee8497b2a388",
            "max": 2137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c08903ba50c4b53a201e1c116524988",
            "value": 2137
          }
        },
        "f58c3967cf944353900a0af28f3844c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f5d6e68016475f92c91b6071fba502",
            "placeholder": "​",
            "style": "IPY_MODEL_2953d7edb1104c15af391e71cff74ce9",
            "value": " 2137/2137 [00:00&lt;00:00, 20840.21 examples/s]"
          }
        },
        "60b2e0da790d4891bb37cdf2df5df586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82dbc1bb964e405196161bc0e001099c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd464d511fd4cbe8ec4bf21b3a126b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae6615de4204e1b8004ee8497b2a388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c08903ba50c4b53a201e1c116524988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98f5d6e68016475f92c91b6071fba502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2953d7edb1104c15af391e71cff74ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21757c62902e4682b747d9ac89bcd354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c6b7fc7fca8428aa66f9d4f1969ef7e",
              "IPY_MODEL_c6e34b0419864143a77c2669ee98a556",
              "IPY_MODEL_877bd4413bb343d2a567f52a56b63d42"
            ],
            "layout": "IPY_MODEL_ed0dc06f55f144ec840c2a6b85b53982"
          }
        },
        "1c6b7fc7fca8428aa66f9d4f1969ef7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a21e4f9d0fbd4ef193ab3cfbe6af41cc",
            "placeholder": "​",
            "style": "IPY_MODEL_5cc69f9ee8044e6ea0c63ddfd002b803",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c6e34b0419864143a77c2669ee98a556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c38bd22899475ca7e2bce7b094d3c3",
            "max": 531,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34672cd1d0114a3cb5d06a60966f4ead",
            "value": 531
          }
        },
        "877bd4413bb343d2a567f52a56b63d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132f43b532ee43eb91bb132af7a4e03d",
            "placeholder": "​",
            "style": "IPY_MODEL_6714559bb0464c57b99db2c85b51d6c5",
            "value": " 531/531 [00:00&lt;00:00, 7.28kB/s]"
          }
        },
        "ed0dc06f55f144ec840c2a6b85b53982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a21e4f9d0fbd4ef193ab3cfbe6af41cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc69f9ee8044e6ea0c63ddfd002b803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c38bd22899475ca7e2bce7b094d3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34672cd1d0114a3cb5d06a60966f4ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "132f43b532ee43eb91bb132af7a4e03d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6714559bb0464c57b99db2c85b51d6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c10d232d61194cb7ae343773b1de29df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_344281bdccf94708bf5edec6c387b8c5",
              "IPY_MODEL_cd0c14d461bd4bdc8ed813278517cfef",
              "IPY_MODEL_6c41a6c095de45bb909b5d47f22beffb"
            ],
            "layout": "IPY_MODEL_93866bd321ac4ca59efcff11b0366b19"
          }
        },
        "344281bdccf94708bf5edec6c387b8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d90488802fc641b58702f6274d7ff0a9",
            "placeholder": "​",
            "style": "IPY_MODEL_ec8feee5ce4245a68a134f762d14cb9c",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "cd0c14d461bd4bdc8ed813278517cfef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f016278a9c484ee0a3a8db6556cd4abe",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b31ac34d4664489ba89bccf34d20eb1",
            "value": 5069051
          }
        },
        "6c41a6c095de45bb909b5d47f22beffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15845a7ccac4df38a9eb62c05cee6eb",
            "placeholder": "​",
            "style": "IPY_MODEL_6d37806b118a44c4ab26d76a00afc28f",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 60.4MB/s]"
          }
        },
        "93866bd321ac4ca59efcff11b0366b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d90488802fc641b58702f6274d7ff0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8feee5ce4245a68a134f762d14cb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f016278a9c484ee0a3a8db6556cd4abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b31ac34d4664489ba89bccf34d20eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b15845a7ccac4df38a9eb62c05cee6eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d37806b118a44c4ab26d76a00afc28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c2ceacdbe79419b99a1b218b15ed256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44380ca694114e59a192208fdb85df54",
              "IPY_MODEL_087afec00fd94d5b840f64551eaf46ba",
              "IPY_MODEL_a4be715bc7c145a9a87a36a716ccb671"
            ],
            "layout": "IPY_MODEL_fb8f5bec7db84f7eb3b48a6ec7707c59"
          }
        },
        "44380ca694114e59a192208fdb85df54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddfdc3bbd4fd492097392411315bf0ae",
            "placeholder": "​",
            "style": "IPY_MODEL_3158098b2542492a89e4465a0b180ea8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "087afec00fd94d5b840f64551eaf46ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889ae9d37f13421fb0be55efac8d0448",
            "max": 649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_660788cf4d584786be40f660556fd78f",
            "value": 649
          }
        },
        "a4be715bc7c145a9a87a36a716ccb671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f46574cdf0d41a0bd0cdf3a3982141f",
            "placeholder": "​",
            "style": "IPY_MODEL_8cca3c75d5b94a81898d3bffa37dd2e0",
            "value": " 649/649 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "fb8f5bec7db84f7eb3b48a6ec7707c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddfdc3bbd4fd492097392411315bf0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3158098b2542492a89e4465a0b180ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889ae9d37f13421fb0be55efac8d0448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660788cf4d584786be40f660556fd78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f46574cdf0d41a0bd0cdf3a3982141f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cca3c75d5b94a81898d3bffa37dd2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04760e2ef19240f28e88964e54a2f495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_386a67706ce148328c76b54ad9f47759",
              "IPY_MODEL_a11017314f0d40228ac602179f7ecc5b",
              "IPY_MODEL_0338c612161f4667ad31321207eb03c1"
            ],
            "layout": "IPY_MODEL_3b0e47c78d3b4dfe94bdb358246a1dce"
          }
        },
        "386a67706ce148328c76b54ad9f47759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_430b98c4e5284e17b0dd4b6d15a5446f",
            "placeholder": "​",
            "style": "IPY_MODEL_cb85e1c467db4c76974b0a19d3ccc7c8",
            "value": "config.json: 100%"
          }
        },
        "a11017314f0d40228ac602179f7ecc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc1062b891084fea9bac9fb63096620c",
            "max": 1415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd9aff1f51874519b83a555171cde809",
            "value": 1415
          }
        },
        "0338c612161f4667ad31321207eb03c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f072453cf544de0b59664d3f4c2ecbe",
            "placeholder": "​",
            "style": "IPY_MODEL_e32bca3f34e94d4d9a01e285899b535a",
            "value": " 1.42k/1.42k [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "3b0e47c78d3b4dfe94bdb358246a1dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "430b98c4e5284e17b0dd4b6d15a5446f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb85e1c467db4c76974b0a19d3ccc7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc1062b891084fea9bac9fb63096620c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9aff1f51874519b83a555171cde809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f072453cf544de0b59664d3f4c2ecbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32bca3f34e94d4d9a01e285899b535a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}